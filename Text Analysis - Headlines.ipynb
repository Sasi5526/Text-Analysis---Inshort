{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning and predicting Sentiment Analyses for News Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapping the Text from inshort website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_urls = ['https://inshorts.com/en/read/technology',\n",
    "             'https://inshorts.com/en/read/sports',\n",
    "             'https://inshorts.com/en/read/world']\n",
    "\n",
    "def build_dataset(seed_urls):\n",
    "    news_data = []\n",
    "    for url in seed_urls:\n",
    "        news_category = url.split('/')[-1]\n",
    "        data = requests.get(url)\n",
    "        soup = BeautifulSoup(data.content, 'html.parser')\n",
    "        \n",
    "        news_articles = [{'news_headline': headline.find('span', \n",
    "                                                         attrs={\"itemprop\": \"headline\"}).string,\n",
    "                          'news_article': article.find('div', \n",
    "                                                       attrs={\"itemprop\": \"articleBody\"}).string,\n",
    "                          'news_category': news_category}\n",
    "                         \n",
    "                            for headline, article in \n",
    "                             zip(soup.find_all('div', \n",
    "                                               class_=[\"news-card-title news-right-box\"]),\n",
    "                                 soup.find_all('div', \n",
    "                                               class_=[\"news-card-content news-right-box\"]))\n",
    "                        ]\n",
    "        news_data.extend(news_articles)\n",
    "        \n",
    "    df =  pd.DataFrame(news_data)\n",
    "    df = df[['news_headline', 'news_article', 'news_category']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_headline</th>\n",
       "      <th>news_article</th>\n",
       "      <th>news_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Uber to fire 3,700 employees worldwide, CEO no...</td>\n",
       "      <td>Ride-hailing company Uber on Wednesday said it...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Airbnb fires 1,900 employees making 25% of its...</td>\n",
       "      <td>Airbnb, the US-based startup that connects tra...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Grimes explains the name of her and Elon Musk'...</td>\n",
       "      <td>A day after Tesla CEO Elon Musk said his baby ...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Aarogya Setu app won't be needed after COVID-1...</td>\n",
       "      <td>MyGov's CEO Abhishek Singh in an interview wit...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Wishing good vibes for all in second half 2020...</td>\n",
       "      <td>Tesla's billionaire CEO Elon Musk, who recentl...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>French hacker says Aarogya Setu putting 'priva...</td>\n",
       "      <td>French hacker Robert Baptiste on Tuesday alert...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>India's Sudhir Krishnaswamy in FB's oversight ...</td>\n",
       "      <td>Facebook has introduced the first 20 members o...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>It's my fault: Samsung heir apologises over co...</td>\n",
       "      <td>Samsung Group heir Jay Y Lee has apologised fo...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Billionaire Elon Musk qualifies for $706 milli...</td>\n",
       "      <td>Tesla CEO Elon Musk has qualified for stock op...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Apple, Google show sample of their COVID-19 ex...</td>\n",
       "      <td>Apple and Google have published sample user in...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       news_headline  \\\n",
       "0  Uber to fire 3,700 employees worldwide, CEO no...   \n",
       "1  Airbnb fires 1,900 employees making 25% of its...   \n",
       "2  Grimes explains the name of her and Elon Musk'...   \n",
       "3  Aarogya Setu app won't be needed after COVID-1...   \n",
       "4  Wishing good vibes for all in second half 2020...   \n",
       "5  French hacker says Aarogya Setu putting 'priva...   \n",
       "6  India's Sudhir Krishnaswamy in FB's oversight ...   \n",
       "7  It's my fault: Samsung heir apologises over co...   \n",
       "8  Billionaire Elon Musk qualifies for $706 milli...   \n",
       "9  Apple, Google show sample of their COVID-19 ex...   \n",
       "\n",
       "                                        news_article news_category  \n",
       "0  Ride-hailing company Uber on Wednesday said it...    technology  \n",
       "1  Airbnb, the US-based startup that connects tra...    technology  \n",
       "2  A day after Tesla CEO Elon Musk said his baby ...    technology  \n",
       "3  MyGov's CEO Abhishek Singh in an interview wit...    technology  \n",
       "4  Tesla's billionaire CEO Elon Musk, who recentl...    technology  \n",
       "5  French hacker Robert Baptiste on Tuesday alert...    technology  \n",
       "6  Facebook has introduced the first 20 members o...    technology  \n",
       "7  Samsung Group heir Jay Y Lee has apologised fo...    technology  \n",
       "8  Tesla CEO Elon Musk has qualified for stock op...    technology  \n",
       "9  Apple and Google have published sample user in...    technology  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = build_dataset(seed_urls)\n",
    "news_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline=news_df['news_headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Airbnb fires 1,900 employees making 25% of its...\n",
       "1     Grimes explains the name of her and Elon Musk'...\n",
       "2     Indians evacuated from abroad will have to dow...\n",
       "3     Amazon VP who quit over staff firings says Goo...\n",
       "4     Wishing good vibes for all in second half 2020...\n",
       "                            ...                        \n",
       "70    Skies in Niger's capital turn red during sand ...\n",
       "71    Hong Kong will never be calm unless violent pr...\n",
       "72    Trump denies US role in 'mercenary incursion' ...\n",
       "73    Trump made 'stupid mistake' by exiting from nu...\n",
       "74    3 rockets hit near Baghdad International Airpo...\n",
       "Name: news_headline, Length: 75, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import LancasterStemmer\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "ls =nltk.stem.LancasterStemmer()\n",
    "import requests \n",
    "\n",
    "import re\n",
    "contractions_dict = {\n",
    "    'didn\\'t': 'did not',\n",
    "    'don\\'t': 'do not',\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"cant\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"didnt\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"doesnt\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"dont\" : \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he had\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i had\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"im\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she had\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they had\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we had\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "    }\n",
    "\n",
    "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "def expand_contractions(s, contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)\n",
    "\n",
    "\n",
    "\n",
    "def strip_html_tags():\n",
    "    soup = BeautifulSoup(content,\"html.parser\")\n",
    "    [s.extract for s in soup(['iframe','script'])]\n",
    "    stripped_text = soup.get_text() \n",
    "    stripped_text=re.sub('[\\r|\\n|\\r\\n]+','\\n',stripped_text)\n",
    "    return stripped_text\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD',text).encode('ascii','ignore').decode('utf-8','ignore')\n",
    "    return text\n",
    "\n",
    "def remove_special_characters(text, remove_digits = False):\n",
    "    patterns = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern,\"\",text)\n",
    "    return text\n",
    "\n",
    "def simple_stemmers(text,stemmer = ps):\n",
    "    text = \" \".join([stemmer.stem(word)for word in text.split()])\n",
    "    return text\n",
    "\n",
    "def expand_contraction(text):\n",
    "    return contraction.fix(text)\n",
    "\n",
    "def spacy_lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ !='-PRON-' else word.text for word in text])\n",
    "\n",
    "def remove_stopwords(text, is_lower_case = False, stopwords = None):\n",
    "    if not stopwords:\n",
    "        stopwords = nltk.corpus.stopwords.words('english')\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens=[token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [tokens for token in tokens if token not in stopwords]\n",
    "    else:\n",
    "         filtered_tokens = [tokens for token in tokens if token.lower() not in stopwords]\n",
    "    filtered_tokens = ' '.join(filtered_tokens)\n",
    "    return filtered_tokens    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def text_pre_processor(text,html_strip=True, accented_char=True,contraction_expansion=True,text_lower_case=True,\n",
    "                       text_stemming=False, text_lemmatization=True,special_char_removal=True, remove_digits=True,\n",
    "                       stopword_removal=True, stopword_list=None): \n",
    "    #strip HTML\n",
    "    if html_strip:\n",
    "        text=strip_html_tags(text)\n",
    "    \n",
    "    #remove extra newlines(often might be present in really noisy text)\n",
    "    text = text.translate(text.maketrans(\"\\n\\t\\r\",\" \"))\n",
    "\n",
    "    #remove accented character\n",
    "    if accented_char_removal:\n",
    "        text = removal_accented_chars(text)\n",
    "    \n",
    "   #expand contraction\n",
    "    if contraction_expansion:\n",
    "         text = spacy_lemmatize_text(text)\n",
    "    \n",
    "   #Lemmatize text\n",
    "    if text_lemmatization:\n",
    "         text = spacy_lemmatize_text(text)\n",
    "    \n",
    "   #remove special characters and \\or digits\n",
    "    if special_char_removal:\n",
    "   #insert space between special characters to isolate them\n",
    "        special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "        text = special_char_pattern.sub(\"\\\\1 \", text)\n",
    "        text = remove_special_characters(text, remove_digits = remove_digits)\n",
    "    \n",
    "   #stem text\n",
    "    if text_stemming and not text_lemmatization:\n",
    "         text = simple_stemming(text)\n",
    "    \n",
    "   #lowercase the text\n",
    "    if text_lower_case:\n",
    "         text = text.lower()\n",
    "\n",
    "   #remove stopwords\n",
    "    if stopword_removal:\n",
    "         text = remove_stopwords(text,is_lower_case = text_lower_case,stopwords=stopword_list)\n",
    "    \n",
    "   #remove extra whitespace\n",
    "    text = re.sub(' +', ' ',text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import textblob\n",
    "stop = stopwords.words('english')\n",
    "from nltk.corpus import opinion_lexicon\n",
    "pos_list=set(opinion_lexicon.positive())\n",
    "neg_list=set(opinion_lexicon.negative())\n",
    "from nltk.tokenize import treebank\n",
    "tokenizer = treebank.TreebankWordTokenizer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from afinn import Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_pre_processor(corpus):\n",
    "    norm_corpus = []\n",
    "    for doc in tqdm.tqdm(corpus):\n",
    "        norm_corpus.append(text_pre_processor(doc))\n",
    "    return norm_corpus\n",
    "\n",
    "def normalize_document(doc):\n",
    "    #Lowercase, remove special char \\whitespace\n",
    "    #remove stopwords\n",
    "    #expand contraction\n",
    "    words= word_tokenize(doc)\n",
    "    doc = \" \".join([word.lower() for word in words if word not in stop])\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]','',doc,re.I|re.A)\n",
    "    doc =doc.strip()\n",
    "    doc = expand_contractions(doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasim\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#split the review into sentence\n",
    "news=news_df[['news_headline','index']]\n",
    "news.rename(columns ={'index':'INDEX'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_headline</th>\n",
       "      <th>INDEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Xiaomi Mi 10 5G with 108MP camera to launch in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Airbnb fires 1,900 employees making 25% of its...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Musk shares 1st pic of son with tattoo filter,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>₹1k fine or up to 6-months jail in Noida for n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Google, Apple ban location tracking in their j...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       news_headline  INDEX\n",
       "0  Xiaomi Mi 10 5G with 108MP camera to launch in...      0\n",
       "1  Airbnb fires 1,900 employees making 25% of its...      1\n",
       "2  Musk shares 1st pic of son with tattoo filter,...      2\n",
       "3  ₹1k fine or up to 6-months jail in Noida for n...      3\n",
       "4  Google, Apple ban location tracking in their j...      4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "news['split'] = news['news_headline'].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_headline</th>\n",
       "      <th>INDEX</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I'm selling almost all physical possessions, w...</td>\n",
       "      <td>0</td>\n",
       "      <td>[I'm selling almost all physical possessions, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Man tries to track 2 packets of snacks bought ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Man tries to track 2 packets of snacks bought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Security lapse at Jio exposed COVID-19 symptom...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Security lapse at Jio exposed COVID-19 sympto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>YouTube deletes conspiracy theorist David Icke...</td>\n",
       "      <td>3</td>\n",
       "      <td>[YouTube deletes conspiracy theorist David Ick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Aarogya Setu adds 'Mitr' portal for free COVID...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Aarogya Setu adds 'Mitr' portal for free COVI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       news_headline  INDEX  \\\n",
       "0  I'm selling almost all physical possessions, w...      0   \n",
       "1  Man tries to track 2 packets of snacks bought ...      1   \n",
       "2  Security lapse at Jio exposed COVID-19 symptom...      2   \n",
       "3  YouTube deletes conspiracy theorist David Icke...      3   \n",
       "4  Aarogya Setu adds 'Mitr' portal for free COVID...      4   \n",
       "\n",
       "                                               split  \n",
       "0  [I'm selling almost all physical possessions, ...  \n",
       "1  [Man tries to track 2 packets of snacks bought...  \n",
       "2  [Security lapse at Jio exposed COVID-19 sympto...  \n",
       "3  [YouTube deletes conspiracy theorist David Ick...  \n",
       "4  [Aarogya Setu adds 'Mitr' portal for free COVI...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_split=news.set_index('INDEX').split.apply(pd.Series).stack().reset_index(level=0).rename(columns={0:'news_headline'})\n",
    "news_split.reset_index(level=0,inplace=True)\n",
    "news_split.rename(columns={'INDEX':'headlines_no','index':'sentence'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>headlines_no</th>\n",
       "      <th>news_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm selling almost all physical possessions, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Man tries to track 2 packets of snacks bought ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Security lapse at Jio exposed COVID-19 symptom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>YouTube deletes conspiracy theorist David Icke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Aarogya Setu adds 'Mitr' portal for free COVID...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>We may not make money this year but won't fire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Google, Apple ban location tracking in their j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>My girlfriend Grimes is mad at me, baby due on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>As always, I am optimistic about Tesla long-te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>US-based Silver Lake to invest ₹5,655.75 crore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Australian govt website reportedly leaks data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Felt lonely after Steve Jobs' death, he left e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>Billionaire Elon Musk welcomes 1st child with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>Tesla CEO Musk puts two homes on sale days aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>Report says Xiaomi tracks users' private phone...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence  headlines_no                                      news_headline\n",
       "0          0             0  I'm selling almost all physical possessions, w...\n",
       "1          0             1  Man tries to track 2 packets of snacks bought ...\n",
       "2          0             2  Security lapse at Jio exposed COVID-19 symptom...\n",
       "3          0             3  YouTube deletes conspiracy theorist David Icke...\n",
       "4          0             4  Aarogya Setu adds 'Mitr' portal for free COVID...\n",
       "5          0             5  We may not make money this year but won't fire...\n",
       "6          0             6  Google, Apple ban location tracking in their j...\n",
       "7          0             7  My girlfriend Grimes is mad at me, baby due on...\n",
       "8          0             8  As always, I am optimistic about Tesla long-te...\n",
       "9          0             9  US-based Silver Lake to invest ₹5,655.75 crore...\n",
       "10         0            10  Australian govt website reportedly leaks data ...\n",
       "11         0            11  Felt lonely after Steve Jobs' death, he left e...\n",
       "12         0            12  Billionaire Elon Musk welcomes 1st child with ...\n",
       "13         0            13  Tesla CEO Musk puts two homes on sale days aft...\n",
       "14         0            14  Report says Xiaomi tracks users' private phone..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_split.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then normalizing the data\n",
    "news_split['news_headline']=news_split['news_headline'].apply(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>headlines_no</th>\n",
       "      <th>news_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>xiaomi mi 10 5g 108mp camera launch india may 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>musk shares 1st pic son tattoo filter  says ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>apple reopen stores australia  austria week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>indians evacuated abroad download aarogya setu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>google  apple ban location tracking joint covi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence  headlines_no                                      news_headline\n",
       "0         0             0    xiaomi mi 10 5g 108mp camera launch india may 8\n",
       "1         0             1  musk shares 1st pic son tattoo filter  says ne...\n",
       "2         0             2        apple reopen stores australia  austria week\n",
       "3         0             3  indians evacuated abroad download aarogya setu...\n",
       "4         0             4  google  apple ban location tracking joint covi..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(news_headline):\n",
    "    from textblob import TextBlob\n",
    "    return TextBlob(news_headline).sentiment.polarity\n",
    "def predict(news_headline):\n",
    "    news_split['score']=news_split['news_headline'].apply(score)\n",
    "    return(news_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>headlines_no</th>\n",
       "      <th>news_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>airbnb fires 1900 employees making 25  global ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>gri ames explains name elon musk s first child...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>indians evacuated abroad download aarogya setu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>amazon vp quit staff firings says google  huaw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>wishing good vibes second half 2020  musk amid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence  headlines_no                                      news_headline\n",
       "0         0             0  airbnb fires 1900 employees making 25  global ...\n",
       "1         0             1  gri ames explains name elon musk s first child...\n",
       "2         0             2  indians evacuated abroad download aarogya setu...\n",
       "3         0             3  amazon vp quit staff firings says google  huaw...\n",
       "4         0             4  wishing good vibes second half 2020  musk amid..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti=predict(news_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>headlines_no</th>\n",
       "      <th>news_headline</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i m selling almost physical possessions  wo nt...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>man tries track 2 packets snacks bought online...</td>\n",
       "      <td>-0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>security lapse jio exposed covid19 symptom che...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>youtube deletes conspiracy theorist david icke...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>aarogya setu adds mitr  portal free covid19 co...</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>bangladesh reports biggest rise daily covid19 ...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>vietnam reports first covid19 case 9 days  tot...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>bangladesh extends lockdown till may 16  covid...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>8 mercenaries killed foiled invasion  venezuel...</td>\n",
       "      <td>-0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>rohingya refugees stranded sea weeks arrive ba...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence  headlines_no                                      news_headline  \\\n",
       "0          0             0  i m selling almost physical possessions  wo nt...   \n",
       "1          0             1  man tries track 2 packets snacks bought online...   \n",
       "2          0             2  security lapse jio exposed covid19 symptom che...   \n",
       "3          0             3  youtube deletes conspiracy theorist david icke...   \n",
       "4          0             4  aarogya setu adds mitr  portal free covid19 co...   \n",
       "..       ...           ...                                                ...   \n",
       "67         0            67  bangladesh reports biggest rise daily covid19 ...   \n",
       "68         0            68  vietnam reports first covid19 case 9 days  tot...   \n",
       "69         0            69  bangladesh extends lockdown till may 16  covid...   \n",
       "70         0            70  8 mercenaries killed foiled invasion  venezuel...   \n",
       "71         0            71  rohingya refugees stranded sea weeks arrive ba...   \n",
       "\n",
       "    score  \n",
       "0   0.000  \n",
       "1  -0.200  \n",
       "2   0.000  \n",
       "3   0.000  \n",
       "4   0.400  \n",
       "..    ...  \n",
       "67  0.000  \n",
       "68  0.125  \n",
       "69  0.000  \n",
       "70 -0.200  \n",
       "71  0.000  \n",
       "\n",
       "[72 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentiment analysis with Text Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.575, subjectivity=0.75)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textblob\n",
    "textblob.TextBlob('I hate this file its not good').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti['Sentiment']=['positive' if score >=0 else 'negative' for score in senti['score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_headline=np.array(senti['news_headline'])\n",
    "sentiment =np.array(senti['Sentiment'])\n",
    "sample=[13,44,69]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i m selling almost physical possessions  wo nt house  billionaire musk',\n",
       "       'man tries track 2 packets snacks bought online 400  loses 2l',\n",
       "       'security lapse jio exposed covid19 symptom checker results online',\n",
       "       'youtube deletes conspiracy theorist david icke s account covid19 clai ams',\n",
       "       'aarogya setu adds mitr  portal free covid19 consultations  booking home lab tests',\n",
       "       'blood covid19 survivors  sold vaccine darknet  researchers',\n",
       "       'maskwearing robots greet covid19 patients japan hotels  wish recovery',\n",
       "       'we may make money year wo nt fire anyone  us software firm s ceo',\n",
       "       'report says xiaomi tracks users  private phone  web activity  company denies',\n",
       "       'australian govt website reportedly leaks data 774000 migrants  criticised',\n",
       "       'my girlfriend gri ames mad  baby due monday  billionaire elon musk',\n",
       "       'usbased silver lake invest 565575 crore jio platforms 115  stake',\n",
       "       'as always  i opti amistic tesla longterm  ceo elon musk',\n",
       "       'felt lonely steve jobs  death  left eternal i ampact others  apple ceo',\n",
       "       'tiktok let users report misleading  information',\n",
       "       'smartphone demand wo nt opti amistic people s income affected  realme',\n",
       "       'microwave steriliser disintegrate  covid19 made pune',\n",
       "       'phones host cocktail live germs  disinfect daily  study',\n",
       "       'lawsuit oracle 4100 women unequal pay approved',\n",
       "       'report xiaomi collecting unnecessary data false  xiaomi india md',\n",
       "       'info 91 mn users indonesia s largest ecomm firm tokopedia stolen',\n",
       "       'google duo may soon let users reach via email address  report',\n",
       "       'tesla extends furlough workers week  reports',\n",
       "       'running around 50 km week destroyed body knees  tiger woods',\n",
       "       'zidane asked i wanted shirt  i said  i want sister   materazzi headbutt',\n",
       "       'i give life anil kumble  gautam gambhir',\n",
       "       'i thought committing suicide three ti ames 2018  mohammad shami',\n",
       "       'michael holding calls world test championship points system ridiculous',\n",
       "       'got s the mountain  sets world deadlift record lifting 501 kgs',\n",
       "       'would devastating india nt tour australia  labuschagne',\n",
       "       'pcb support 1stclass cricketers  match officials amid covid19 lockdown',\n",
       "       'serie a begin individual training sessions monday',\n",
       "       'covid19 i ampact serious unless cricket resumes empty stadiums  bacher',\n",
       "       'it s opportunity fix australia s domestic cricket setup  coach langer',\n",
       "       'wasi am akram  babar azam conduct online sessions pak women s team',\n",
       "       'la liga begin testing players covid19 resuming training',\n",
       "       'women s hockey team raises 20 lakh relief efforts fitness challenge',\n",
       "       'was team effort  proud moment  pujara recalls 201819 test series win aus',\n",
       "       'neymar ready take 50  pay cut move barcelona  report',\n",
       "       'people know cricket  rijiju viral 100m run videos',\n",
       "       'kl rahul proper wicketkeeper  s technically sound  explayer dasgupta',\n",
       "       'mi playyourrole setup  csk faith players  ability  rayudu',\n",
       "       'extremely motivated play three formats  faf du plessis',\n",
       "       'laxman nt care s bowling pace  made pay  brett lee',\n",
       "       'it sachin 2011 world cup  suresh raina',\n",
       "       'i would love play kkr ipl till retirement  andre russell',\n",
       "       'mohammad yousuf ranks tendulkar lara  ponting  kallis  sangakkara',\n",
       "       'other teams nt take us lightly anymore  mithali raj',\n",
       "       'india lodges protest pak pak supreme court s order gilgitbaltistan',\n",
       "       'govt facilitate return indians stranded abroad may 7',\n",
       "       'us man tries selfisolate private disney island closed public  arrested',\n",
       "       'italy reports lowest daily covid19 death toll since 1st day lockdown 174 die',\n",
       "       'australia  new zealand consider travel bubble  lockdown eases',\n",
       "       'confident going coronavirus vaccine year end  trump',\n",
       "       'goat  fruit test ve coronavirus tanzania  president questions kits',\n",
       "       'vacate occupied territories  india pakistan supreme court order',\n",
       "       'shots fired n korea s korean guard post likely accidental  us',\n",
       "       'global covid19 cases cross 35 lakh  deaths rise nearly 248 lakh',\n",
       "       'russia s covid19 cases rise 10000 second day',\n",
       "       'brazil 1st latin america report 1 lakh covid19 cases',\n",
       "       '13rd 500 random covid19 tests found ve afghanistan',\n",
       "       'china hid severity coronavirus pandemic january  us',\n",
       "       'japan extends state emergency till may 31 due covid19',\n",
       "       'italy eases nationwide covid19 lockdown 56 days',\n",
       "       'coronavirus cases pakistan exceed 20000mark',\n",
       "       'it s humanity virus  uk pm johnson covid19 global summit',\n",
       "       'spain allows citizens leave home first ti ame 7 weeks',\n",
       "       'bangladesh reports biggest rise daily covid19 cases 665',\n",
       "       'vietnam reports first covid19 case 9 days  total cases 271',\n",
       "       'bangladesh extends lockdown till may 16  covid19 cases cross 10000',\n",
       "       '8 mercenaries killed foiled invasion  venezuelan govt',\n",
       "       'rohingya refugees stranded sea weeks arrive bangladesh'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEWS_HEADLINE france accuses apple refusing help covid19 tracking app\n",
      "SENTIMENT positive\n",
      "Predicted Sentiment polarity 0.0\n",
      "------------------------------------------------------------\n",
      "NEWS_HEADLINE extremely motivated play three formats  faf du plessis\n",
      "SENTIMENT negative\n",
      "Predicted Sentiment polarity -0.125\n",
      "------------------------------------------------------------\n",
      "NEWS_HEADLINE new zealand safe advantage  welcome investments  pm\n",
      "SENTIMENT positive\n",
      "Predicted Sentiment polarity 0.4787878787878788\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for news_headline,sentiment in zip (news_headline[sample],sentiment[sample]):\n",
    "    print('NEWS_HEADLINE',news_headline)\n",
    "    print('SENTIMENT',sentiment)\n",
    "    print('Predicted Sentiment polarity',textblob.TextBlob(news_headline).sentiment.polarity)\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_polarity=[textblob.TextBlob(news_headline).sentiment.polarity for news_headline in news_headline]\n",
    "predicted_sentiments=['positive'if score >= 0.1 else 'negative' for score in sentiment_polarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentiment analysis with AFINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "afn = Afinn(emoticons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afn.score('I love it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "afnn=pd.DataFrame(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>news_headline</th>\n",
       "      <th>news_article</th>\n",
       "      <th>news_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Airbnb fires 1,900 employees making 25% of its...</td>\n",
       "      <td>Airbnb, the US-based startup that connects tra...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Grimes explains the name of her and Elon Musk'...</td>\n",
       "      <td>A day after Tesla CEO Elon Musk said his baby ...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Indians evacuated from abroad will have to dow...</td>\n",
       "      <td>Indians stranded abroad, who will be brought b...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Amazon VP who quit over staff firings says Goo...</td>\n",
       "      <td>The Amazon VP who quit over the firm's decisio...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Wishing good vibes for all in second half 2020...</td>\n",
       "      <td>Tesla's billionaire CEO Elon Musk, who recentl...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>Skies in Niger's capital turn red during sand ...</td>\n",
       "      <td>Skies in Niamey, the capital city of Niger, tu...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>Hong Kong will never be calm unless violent pr...</td>\n",
       "      <td>China's Hong Kong affairs office on Wednesday ...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>Trump denies US role in 'mercenary incursion' ...</td>\n",
       "      <td>US President Donald Trump has said that his go...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>Trump made 'stupid mistake' by exiting from nu...</td>\n",
       "      <td>US President Donald Trump \"made a stupid mista...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>3 rockets hit near Baghdad International Airpo...</td>\n",
       "      <td>Three rockets on Wednesday landed on the perim...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                      news_headline  \\\n",
       "0       0  Airbnb fires 1,900 employees making 25% of its...   \n",
       "1       1  Grimes explains the name of her and Elon Musk'...   \n",
       "2       2  Indians evacuated from abroad will have to dow...   \n",
       "3       3  Amazon VP who quit over staff firings says Goo...   \n",
       "4       4  Wishing good vibes for all in second half 2020...   \n",
       "..    ...                                                ...   \n",
       "70     70  Skies in Niger's capital turn red during sand ...   \n",
       "71     71  Hong Kong will never be calm unless violent pr...   \n",
       "72     72  Trump denies US role in 'mercenary incursion' ...   \n",
       "73     73  Trump made 'stupid mistake' by exiting from nu...   \n",
       "74     74  3 rockets hit near Baghdad International Airpo...   \n",
       "\n",
       "                                         news_article news_category  \n",
       "0   Airbnb, the US-based startup that connects tra...    technology  \n",
       "1   A day after Tesla CEO Elon Musk said his baby ...    technology  \n",
       "2   Indians stranded abroad, who will be brought b...    technology  \n",
       "3   The Amazon VP who quit over the firm's decisio...    technology  \n",
       "4   Tesla's billionaire CEO Elon Musk, who recentl...    technology  \n",
       "..                                                ...           ...  \n",
       "70  Skies in Niamey, the capital city of Niger, tu...         world  \n",
       "71  China's Hong Kong affairs office on Wednesday ...         world  \n",
       "72  US President Donald Trump has said that his go...         world  \n",
       "73  US President Donald Trump \"made a stupid mista...         world  \n",
       "74  Three rockets on Wednesday landed on the perim...         world  \n",
       "\n",
       "[75 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Uber to fire 3,700 employees worldwide, CEO no...\n",
       "1     Airbnb fires 1,900 employees making 25% of its...\n",
       "2     Grimes explains the name of her and Elon Musk'...\n",
       "3     Indians evacuated from abroad will have to dow...\n",
       "4     Amazon VP who quit over staff firings says Goo...\n",
       "                            ...                        \n",
       "70     Iran's state broadcaster influenced 2014 Scot...\n",
       "71    3 rockets hit near Baghdad International Airpo...\n",
       "72    Trump made 'stupid mistake' by exiting from nu...\n",
       "73    Hong Kong will never be calm unless violent pr...\n",
       "74    Skies in Niger's capital turn red during sand ...\n",
       "Name: news_headline, Length: 75, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afnn.loc[:,\"news_headline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(news_headline):\n",
    "    from afinn import Afinn\n",
    "    return afn.score(news_headline)\n",
    "def predict(news_headline):\n",
    "    afnn['score']=afnn['news_headline'].apply(score)\n",
    "    return(afnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "afnn_senti=predict(afnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "afnn_senti['sentiment']=['positive' if score >=0 else 'negative' for score in afnn_senti['score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_headline=np.array(afnn_senti['news_headline'])\n",
    "sentiment =np.array(afnn_senti['sentiment'])\n",
    "sample=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for news_headline,sentiment in zip (news_headline[sample],sentiment[sample]):\n",
    "    print(\"NEWS_HEADLINE\",news_headline)\n",
    "    print(\"SENTIMENT\",sentiment)\n",
    "    print(\"Predicted Sentiment polarity\",afn.score(news_headline).sentiment.polarity)\n",
    "    print('-'*60)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_polarity=[textblob.TextBlob(news_headline).sentiment.polarity for news_headline in news_headline]\n",
    "predicted_sentiments=['positive'if score >= 0.2 else 'negative' for score in sentiment_polarity]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analyses using Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader=pd.DataFrame(news_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     uber fire 3700 employees worldwide  ceo take b...\n",
       "1     airbnb fires 1900 employees making 25  global ...\n",
       "2     gri ames explains name elon musk s first child...\n",
       "3     indians evacuated abroad download aarogya setu...\n",
       "4     amazon vp quit staff firings says google  huaw...\n",
       "                            ...                        \n",
       "71    iran s state broadcaster influenced 2014 scott...\n",
       "72    3 rockets hit near baghdad international airpo...\n",
       "73    trump made stupid mistake  exiting nuclear dea...\n",
       "74    hong kong never calm unless violent protesters...\n",
       "75    skies niger s capital turn red sand storm  vid...\n",
       "Name: news_headline, Length: 76, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader.loc[:,\"news_headline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(news_headline):\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "    return vader.polarity_scores(news_headline)['compound']\n",
    "def predict(news_headline):\n",
    "    vader['score']=vader['news_headline'].apply(score)\n",
    "    return(vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_senti=predict(vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_senti['sentiment']=['positive' if score >=0 else 'negative' for score in vader_senti['score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_headline=np.array(vader_senti['news_headline'])\n",
    "sentiment =np.array(vader_senti['score'])\n",
    "sample=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_vader_lexicon(news_headline,\n",
    "                                    threshold=0.1,\n",
    "                                    verbose=False):\n",
    "    #analyse the sentiment for review\n",
    "    analyzer=SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(news_headline)\n",
    "    #get aggregrate scores and final sentiment\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 'positive' if agg_score >= threshold\\\n",
    "                                    else 'negative'\n",
    "    if verbose:\n",
    "        #display detailed sentiment statistics\n",
    "        positive = str(round(scores['pos'], 2)*100)+'%'\n",
    "        final = round(agg_score, 2)\n",
    "        negative = str(round(scores['neg'], 2)*100)+'%'\n",
    "        neutral = str(round(scores['neu'], 2)*100)+'%'\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment,final,positive,\n",
    "                                        negative,neutral]],\n",
    "                                        columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'],\n",
    "                                                                      ['Predicted Sentiment','Polarity Score',\n",
    "                                                                        'Positive', 'Negative' 'Neutral']],\n",
    "                                                              codes=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
    "        print(sentiment_frame)\n",
    "        \n",
    "    return final_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for news_headline,sentiment in zip (news_headline[sample],sentiment[sample]):\n",
    "    print('NEWS_HEADLINE',news_headline)\n",
    "    print('SENTIMENT',sentiment)\n",
    "    pred = analyze_sentiment_vader_lexicon (news_headline,threshold=0.4, verbose =True)\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_polarity=[textblob.TextBlob(news_headline).sentiment.polarity for news_headline in news_headline]\n",
    "predicted_sentiments=['positive'if score >= 0.2 else 'negative' for score in sentiment_polarity]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a sentimental analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c2e68a4b8f3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnews_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnews_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-0539b59e1558>\u001b[0m in \u001b[0;36mbuild_dataset\u001b[1;34m(seed_urls)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseed_urls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mnews_category\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "news_df = build_dataset(seed_urls)\n",
    "news_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_headline</th>\n",
       "      <th>news_article</th>\n",
       "      <th>news_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Uber to fire 3,700 employees worldwide, CEO no...</td>\n",
       "      <td>Ride-hailing company Uber on Wednesday said it...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Airbnb fires 1,900 employees making 25% of its...</td>\n",
       "      <td>Airbnb, the US-based startup that connects tra...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Grimes explains the name of her and Elon Musk'...</td>\n",
       "      <td>A day after Tesla CEO Elon Musk said his baby ...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Amazon VP who quit over staff firings says Goo...</td>\n",
       "      <td>The Amazon VP who quit over the firm's decisio...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Indians evacuated from abroad will have to dow...</td>\n",
       "      <td>Indians stranded abroad, who will be brought b...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       news_headline  \\\n",
       "0  Uber to fire 3,700 employees worldwide, CEO no...   \n",
       "1  Airbnb fires 1,900 employees making 25% of its...   \n",
       "2  Grimes explains the name of her and Elon Musk'...   \n",
       "3  Amazon VP who quit over staff firings says Goo...   \n",
       "4  Indians evacuated from abroad will have to dow...   \n",
       "\n",
       "                                        news_article news_category  \n",
       "0  Ride-hailing company Uber on Wednesday said it...    technology  \n",
       "1  Airbnb, the US-based startup that connects tra...    technology  \n",
       "2  A day after Tesla CEO Elon Musk said his baby ...    technology  \n",
       "3  The Amazon VP who quit over the firm's decisio...    technology  \n",
       "4  Indians stranded abroad, who will be brought b...    technology  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "import tqdm\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    [s.extract() for s in soup(['iframe', 'script'])]\n",
    "    stripped_text = soup.get_text()\n",
    "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "    return stripped_text\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "import re\n",
    "contractions_dict = {\n",
    "    'didn\\'t': 'did not',\n",
    "    'don\\'t': 'do not',\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"cant\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"didnt\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"doesnt\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"dont\" : \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he had\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i had\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"im\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she had\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they had\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we had\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "    }\n",
    "\n",
    "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "def expand_contractions(s, contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)\n",
    "\n",
    "\n",
    "def pre_process_corpus(docs):\n",
    "    norm_docs = []\n",
    "    for doc in tqdm.tqdm(docs):\n",
    "        doc = strip_html_tags(doc)\n",
    "        doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "        doc = doc.lower()\n",
    "        doc = remove_accented_chars(doc)\n",
    "        doc = expand_contractions(doc)\n",
    "        # lower case and remove special characters\\whitespaces\n",
    "        doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        doc = doc.strip()  \n",
    "        norm_docs.append(doc)\n",
    "  \n",
    "    return norm_docs\n",
    "\n",
    "\n",
    "import tqdm\n",
    "def corpus_pre_processor(corpus):\n",
    "    norm_corpus = []\n",
    "    for doc in tqdm.tqdm(corpus):\n",
    "        norm_corpus.append(normalize_document(doc))\n",
    "    return norm_corpus\n",
    "def normalize_corpus(doc):\n",
    "    #Lowercase, remove special char \\whitespace\n",
    "    #remove stopwords\n",
    "    #expand contraction\n",
    "    words= word_tokenize(doc)\n",
    "    doc = \" \".join([word.lower() for word in words if word not in stop])\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]','',doc,re.I|re.A)\n",
    "    doc =doc.strip()\n",
    "    doc = expand_contractions(doc)\n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing ito train and test\n",
    "headline= news_df['news_headline'].values\n",
    "category = news_df['news_category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_headline=headline[:60]\n",
    "train_category = category[:60]\n",
    "\n",
    "test_headline = headline[60:]\n",
    "test_category = category[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 3117.48it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 2233.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 78.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "norm_train_headlines = pre_process_corpus(train_headline)\n",
    "norm_test_headlines = pre_process_corpus(test_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#biuld BOW\n",
    "cv = CountVectorizer(binary = False, min_df = 5, max_df = 1.0, ngram_range=(1,2))\n",
    "\n",
    "cv_train_features = cv.fit_transform(norm_train_headlines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test_features = cv.transform(norm_test_headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty='l2',max_iter=500,C=1,solver='lbfgs')\n",
    "lr.fit (cv_train_features,train_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions = lr.predict(cv_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sports       0.00      0.00      0.00       0.0\n",
      "  technology       0.00      0.00      0.00       0.0\n",
      "       world       0.00      0.00      0.00      15.0\n",
      "\n",
      "    accuracy                           0.00      15.0\n",
      "   macro avg       0.00      0.00      0.00      15.0\n",
      "weighted avg       0.00      0.00      0.00      15.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasim\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\sasim\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "labels = ['sports','technology','world']\n",
    "print(classification_report(test_category,lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['sports','technology','world']\n",
    "pd.DataFrame(confusion_matrix(test_category,lr_predictions),index = labels,columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_category,lr_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For TFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(use_idf =True, min_df=5,max_df=1.0,ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 3198.83it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 3364.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "norm_train_reviews = pre_process_corpus(train_headline)\n",
    "norm_test_reviews = pre_process_corpus(test_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_train_features = tv.fit_transform(norm_train_headlines)\n",
    "tv_test_features = tv.transform(norm_test_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(tv_train_features,train_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions = lr.predict(tv_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sports       0.00      0.00      0.00       0.0\n",
      "  technology       0.00      0.00      0.00       0.0\n",
      "       world       0.00      0.00      0.00      15.0\n",
      "\n",
      "    accuracy                           0.00      15.0\n",
      "   macro avg       0.00      0.00      0.00      15.0\n",
      "weighted avg       0.00      0.00      0.00      15.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasim\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\sasim\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "labels = ['sports','technology','world']\n",
    "print(classification_report(test_category,lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sports</th>\n",
       "      <th>technology</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sports</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>technology</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>world</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sports  technology  world\n",
       "sports           0           0      0\n",
       "technology       0           0      0\n",
       "world            6           9      0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['sports','technology','world']\n",
    "pd.DataFrame(confusion_matrix(test_category,lr_predictions),index = labels,columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_category,lr_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing ito train and test\n",
    "headline_N= news_df['news_headline'].values\n",
    "category_N = news_df['news_category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_headline_N=headline_N[:60]\n",
    "train_category_N = category_N[:60]\n",
    "\n",
    "test_headline_N = headline_N[60:]\n",
    "test_category_N = category_N[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 626.68it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 1880.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 130 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "norm_train_headlines_N = pre_process_corpus(train_headline_N)\n",
    "norm_test_headlines_N = pre_process_corpus(test_headline_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.98 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#biuld BOW\n",
    "cv = CountVectorizer(binary = False, min_df = 5, max_df = 1.0, ngram_range=(1,2))\n",
    "\n",
    "cv_train_features_N = cv.fit_transform(norm_train_headlines_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test_features_N = cv.transform(norm_test_headlines_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "lr_N=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_N.fit(cv_train_features_N,train_category_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions_N = lr.predict(cv_test_features_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_category_N,lr_predictions_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sports       0.00      0.00      0.00         0\n",
      "       world       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.50      0.47      0.48        15\n",
      "weighted avg       1.00      0.93      0.97        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasim\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "labels = ['sports','technology','world']\n",
    "print(classification_report(test_category_N,lr_predictions_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sports</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sports</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>world</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sports  world\n",
       "sports       0      0\n",
       "world        1     14"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['sports','world']\n",
    "pd.DataFrame(confusion_matrix(test_category_N,lr_predictions_N),index = labels,columns = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tfifd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(use_idf =True, min_df=5,max_df=1.0,ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 2148.59it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 1501.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 95.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "norm_train_reviews_N = pre_process_corpus(train_headline_N)\n",
    "norm_test_reviews_N = pre_process_corpus(test_headline_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tv_train_features_N = tv.fit_transform(norm_train_headlines_N)\n",
    "tv_test_features_N = tv.transform(norm_test_headlines_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lr_N.fit(tv_train_features_N,train_category_N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions_Nt = lr.predict(tv_test_features_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_category_N,lr_predictions_Nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sports       0.00      0.00      0.00         0\n",
      "       world       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.50      0.47      0.48        15\n",
      "weighted avg       1.00      0.93      0.97        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasim\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "labels = ['sports','technology','world']\n",
    "print(classification_report(test_category_N,lr_predictions_Nt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sports</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sports</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>world</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sports  world\n",
       "sports       0      0\n",
       "world        1     14"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['sports','world']\n",
    "pd.DataFrame(confusion_matrix(test_category_N,lr_predictions_Nt),index = labels,columns = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing ito train and test\n",
    "headline_D= news_df['news_headline'].values\n",
    "category_D = news_df['news_category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_headline_D=headline_D[:60]\n",
    "train_category_D = category_D[:60]\n",
    "\n",
    "test_headline_D = headline_D[60:]\n",
    "test_category_D = category_D[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 5468.57it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 4998.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "norm_train_headlines_D = pre_process_corpus(train_headline_D)\n",
    "norm_test_headlines_D = pre_process_corpus(test_headline_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#biuld BOW\n",
    "cv = CountVectorizer(binary = False, min_df = 5, max_df = 1.0, ngram_range=(1,2))\n",
    "\n",
    "cv_train_features_D = cv.fit_transform(norm_train_headlines_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test_features_D = cv.transform(norm_test_headlines_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "lr_D=DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_D.fit(cv_train_features_D,train_headline_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test_features_D=cv_test_features_D.toarray()\n",
    "lr_predictions_D = lr.predict(cv_test_features_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_category_D,lr_predictions_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sports       0.00      0.00      0.00         0\n",
      "       world       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.50      0.47      0.48        15\n",
      "weighted avg       1.00      0.93      0.97        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasim\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "labels = ['sports','technology','world']\n",
    "print(classification_report(test_category_D,lr_predictions_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sports</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sports</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>world</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sports  world\n",
       "sports       0      0\n",
       "world        1     14"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['sports','world']\n",
    "pd.DataFrame(confusion_matrix(test_category_D,lr_predictions_D),index = labels,columns = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tfifd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(use_idf =True, min_df=5,max_df=1.0,ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 5468.10it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 5012.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "norm_train_reviews_DT = pre_process_corpus(train_headline_D)\n",
    "norm_test_reviews_DT = pre_process_corpus(test_headline_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tv_train_features_DT = tv.fit_transform(norm_train_headlines_D)\n",
    "tv_test_features_DT = tv.transform(norm_test_headlines_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_train_features_DT=tv_train_features_DT.toarray()\n",
    "lr_N.fit(tv_train_features_DT,train_category_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_test_features_DT=tv_test_features_DT.toarray()\n",
    "lr_predictions_Dt = lr.predict(tv_test_features_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_category_D,lr_predictions_Dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sports       0.00      0.00      0.00         0\n",
      "       world       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.50      0.47      0.48        15\n",
      "weighted avg       1.00      0.93      0.97        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasim\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "labels = ['sports','technology','world']\n",
    "print(classification_report(test_category_D,lr_predictions_Dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sports</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sports</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>world</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sports  world\n",
       "sports       0      0\n",
       "world        1     14"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['sports','world']\n",
    "pd.DataFrame(confusion_matrix(test_category_D,lr_predictions_Dt),index = labels,columns = labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
